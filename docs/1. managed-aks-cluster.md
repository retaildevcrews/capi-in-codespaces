# Provision AKS Cluster using CAPZ

Cluster API Provider Azure (CAPZ) experimentally supports managing Azure Kubernetes Service (AKS) clusters. CAPZ implements this with three custom resources:

- AzureManagedControlPlane
- AzureManagedCluster
- AzureManagedMachinePool

## Deploy with clusterctl

- A clusterctl flavor exists to deploy an AKS cluster with CAPZ. This flavor requires the following environment variables to be set before executing clusterctl.

  ```bash

  # Kubernetes values
  export CLUSTER_NAME=capz-$GITHUB_USER-aks
  export WORKER_MACHINE_COUNT=1
  # validate valid kubernetes version for a given location by running
  # az aks get-versions -l eastus
  export KUBERNETES_VERSION="v1.25.2"

  ```

  ```bash

  # Azure values
  export AZURE_LOCATION="eastus"
  export AZURE_RESOURCE_GROUP=$CLUSTER_NAME-rg

  ```

- Validate other Azure environment varaibles set by the devcontainer

  ```bash

   env | grep AZURE

  ```

  - AZURE_SUBSCRIPTION_ID
  - AZURE_SUBSCRIPTION_ID_B64
  - AZURE_CLIENT_ID
  - AZURE_CLIENT_ID_B64
  - AZURE_CLIENT_SECRET
  - AZURE_CLIENT_SECRET_B64
  - AZURE_TENANT_ID
  - AZURE_TENANT_ID_B64

- Generate the cluster configuration

  ```bash

  clusterctl generate cluster ${CLUSTER_NAME} \
  --kubernetes-version ${KUBERNETES_VERSION} \
  --control-plane-machine-count=1 \
  --worker-machine-count=${WORKER_MACHINE_COUNT} \
  --flavor aks \
  > aks-cluster.yaml

  ```

- Apply the workload cluster

  ```bash

  kubectl apply -f aks-cluster.yaml

  ```

- Access the workload AKS cluster

  ```bash

  # validate the workload cluster
  kubectl get cluster

  # validate cluster and its resources
  clusterctl describe cluster $CLUSTER_NAME

  # verify the control plane is up
  kubectl get kubeadmcontrolplane

  ```

- After the control plane node is up and running, we can retrieve the workload cluster Kubeconfig:

  ```bash

  clusterctl get kubeconfig $CLUSTER_NAME > $CLUSTER_NAME.kubeconfig

  # update KUBECONFIG so kubectl can access the different config files.
  # useful for easily switching kube contexts
  export KUBECONFIG=~/.kube/config:/workspaces/capi-in-codespaces/$CLUSTER_NAME.kubeconfig

  kubectl config rename-context $CLUSTER_NAME-admin@$CLUSTER_NAME $CLUSTER_NAME

  ```

- The control plane wonâ€™t be `Ready` until we install a CNI, deploy a CNI solution by running:

   ```bash

   kubectl --context=$CLUSTER_NAME \
   apply -f https://raw.githubusercontent.com/projectcalico/calico/v3.24.1/manifests/calico.yaml

   ```

  After a short while, nodes should be running and in `Ready` state, check the status of workload cluster by running:

  ```bash

  kubectl --context=$CLUSTER_NAME get nodes

  ```
